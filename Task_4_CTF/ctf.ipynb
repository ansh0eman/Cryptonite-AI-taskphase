{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Architecture Overview\n",
        "1. Input Layer: accepts Input features\n",
        "2. Hidden Layers: Multiple layers with custom activation functions.\n",
        "3. Output Layer: Produces the classification result.\n",
        "\n",
        "#Flag Encoding\n",
        "1. Custom Activation Function: We create an activation function that encodes a part of the flag by manipulating its output based on the flag's characters.\n",
        "2. Hidden Layer Modifications: The flag is also encoded in the weights and biases of one or more hidden layers."
      ],
      "metadata": {
        "id": "zzzvxeNskzs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpiMlCWalg2F",
        "outputId": "afbf7e2a-c63a-4d32-9b02-e99dc38e06c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwaSkT0xhDwP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Layer\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomActivation(Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomActivation, self).__init__()\n",
        "        self.flag = \"Ansh0eXAquila\"\n",
        "        # Use the sum of ASCII values of the first three characters as a divisor\n",
        "        self.flag_value = sum(ord(char) for char in self.flag[:3])\n",
        "        # Another secret for encoding, e.g., a specific pattern\n",
        "        # based on a condition\n",
        "        # add secret pattern only when x > 0 else let it be\n",
        "        self.secret_pattern = 0.12345\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.math.tanh(inputs)\n",
        "        x = x / self.flag_value\n",
        "        # Add a pattern under specific conditions (e.g., positive inputs)\n",
        "        condition = tf.greater(x, 0)\n",
        "        x = tf.where(condition, x + self.secret_pattern, x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7giUIiNClTdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Architecture\n",
        "A basic cat/non-cat classifier\n",
        "\n",
        "3 hidden layers with 128, 64, 32 nodes respectively and a final output layer with sigmoid activation"
      ],
      "metadata": {
        "id": "C_UJIEUPl_-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CatClassifier(Model):\n",
        "    def __init__(self):\n",
        "        super(CatClassifier, self).__init__()\n",
        "        self.hidden1 = Dense(128, activation=None)\n",
        "        self.hidden2 = Dense(64, activation=None)\n",
        "        self.custom_activation1 = CustomActivation()\n",
        "        self.custom_activation2 = CustomActivation()\n",
        "        self.hidden3 = Dense(32, activation=None)\n",
        "        self.output_layer = Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.hidden1(inputs)\n",
        "        x = self.custom_activation1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.custom_activation2(x)\n",
        "        x = self.hidden3(x)\n",
        "        return self.output_layer(x)\n"
      ],
      "metadata": {
        "id": "NBMFs7G2l9jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flag Encoding\n",
        "\n",
        "encode different parts of flag in the biases of various hidden layery"
      ],
      "metadata": {
        "id": "GKxv_ZpDmeru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the flag into the biases and weights of the network\n",
        "def encode_flag_across_layers(model, flag):\n",
        "    # Convert flag to ASCII values\n",
        "    ascii_values = [ord(char) for char in flag]\n",
        "\n",
        "    # Extract weights and biases from all layers\n",
        "    weights1, biases1 = model.hidden1.get_weights()\n",
        "    weights2, biases2 = model.hidden2.get_weights()\n",
        "    weights3, biases3 = model.hidden3.get_weights()\n",
        "\n",
        "    # Print to debug and verify\n",
        "    print(\"weights1 shape:\", weights1.shape)\n",
        "    print(\"biases1 shape:\", biases1.shape)\n",
        "    print(\"weights2 shape:\", weights2.shape)\n",
        "    print(\"biases2 shape:\", biases2.shape)\n",
        "    print(\"weights3 shape:\", weights3.shape)\n",
        "    print(\"biases3 shape:\", biases3.shape)\n",
        "\n",
        "    # Flatten weights and biases for easier manipulation\n",
        "    bias1 = biases1\n",
        "    bias2 = biases2\n",
        "    bias3 = biases3\n",
        "    weights1 = weights1.flatten()\n",
        "    weights2 = weights2.flatten()\n",
        "    weights3 = weights3.flatten()\n",
        "\n",
        "    # Concatenate weights and biases\n",
        "    combined = np.concatenate([bias1, bias2, bias3, weights1, weights2, weights3])\n",
        "\n",
        "    # Encode ASCII values into the combined array\n",
        "    for i, value in enumerate(ascii_values):\n",
        "        if i < len(combined):\n",
        "            combined[i] += value\n",
        "\n",
        "    # Split the combined array back into biases and weights\n",
        "    bias1_end = len(bias1)\n",
        "    bias2_end = bias1_end + len(bias2)\n",
        "    bias3_end = bias2_end + len(bias3)\n",
        "    weights1_end = bias3_end + len(weights1)\n",
        "    weights2_end = weights1_end + len(weights2)\n",
        "    weights3_end = weights2_end + len(weights3)\n",
        "\n",
        "    bias1 = combined[:bias1_end]\n",
        "    bias2 = combined[bias1_end:bias2_end]\n",
        "    bias3 = combined[bias2_end:bias3_end]\n",
        "    weights1 = combined[bias3_end:weights1_end]\n",
        "    weights2 = combined[weights1_end:weights2_end]\n",
        "    weights3 = combined[weights2_end:]\n",
        "\n",
        "    # Reshape weights back to their original shapes\n",
        "    weights1 = weights1.reshape(model.hidden1.weights[0].shape)\n",
        "    weights2 = weights2.reshape(model.hidden2.weights[0].shape)\n",
        "    weights3 = weights3.reshape(model.hidden3.weights[0].shape)\n",
        "\n",
        "    # Assign modified biases and weights back to the model\n",
        "    model.hidden1.set_weights([weights1, bias1])\n",
        "    model.hidden2.set_weights([weights2, bias2])\n",
        "    model.hidden3.set_weights([weights3, bias3])\n"
      ],
      "metadata": {
        "id": "H3ZfZUSMmc8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = CatClassifier()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "Mb4wqOrgsRk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy data for demonstration (not for actual training)\n",
        "X_dummy = np.random.rand(10, 128).astype(np.float32)\n",
        "y_dummy = np.random.randint(0, 2, size=(10, 1)).astype(np.float32)\n",
        "\n",
        "# Fit the model (optional, for demonstration purposes)\n",
        "model.fit(X_dummy, y_dummy, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz8PUpIbslUl",
        "outputId": "6e1b0aa7-389e-4bb4-f736-f9a50581910b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e2e0df88f40>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the flag in the weights and biases\n",
        "encode_flag_across_layers(model, \"Ansh0eXAquila\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGPBz__0sVst",
        "outputId": "da141f85-9e20-4aab-d8da-b2de40452f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights1 shape: (128, 128)\n",
            "biases1 shape: (128,)\n",
            "weights2 shape: (128, 64)\n",
            "biases2 shape: (64,)\n",
            "weights3 shape: (64, 32)\n",
            "biases3 shape: (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vXtaxeMuS2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}